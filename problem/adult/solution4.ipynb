{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "* [Adult Data Set](https://archive.ics.uci.edu/ml/datasets/Adult) (UCI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as pp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "\n",
    "from common import Dataset, column_variants, encode_categorical, load_data\n",
    "from common import compute_confusion, plot_confusion\n",
    "\n",
    "np.random.seed(0)\n",
    "pp.rcParams.update({'figure.max_open_warning': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([load_data('data/train.csv'),\n",
    "                  load_data('data/test.csv', skiprows=1)])\n",
    "\n",
    "data.dropna(inplace=True)\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "data.info()\n",
    "sb.countplot(data['Income'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "redundant = [\n",
    "    'CapitalGain',\n",
    "    'CapitalLoss',\n",
    "    'EducationNumber',\n",
    "    'FinalSamplingWeight',\n",
    "]\n",
    "\n",
    "categorical = [\n",
    "    'Education',\n",
    "    'MaritalStatus',\n",
    "    'NativeCountry',\n",
    "    'Occupation',\n",
    "    'Race',\n",
    "    'Relationship',\n",
    "    'Sex',\n",
    "    'WorkClass',\n",
    "]\n",
    "\n",
    "data.drop(redundant, axis=1, inplace=True)\n",
    "\n",
    "for name in categorical:\n",
    "    data = encode_categorical(data, name)\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    'Original': Dataset(data),\n",
    "    'Oversampled': Dataset(data, oversample=True),\n",
    "    'Undersampled': Dataset(data, undersample=True),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "models = {\n",
    "    'Adaptive boosting':\n",
    "        lambda: AdaBoostClassifier(n_estimators=50),\n",
    "    'Decision tree':\n",
    "        lambda: DecisionTreeClassifier(max_depth=10),\n",
    "    'Gaussian naive Bayes':\n",
    "        lambda: GaussianNB(),\n",
    "    'K-nearest neighbors':\n",
    "        lambda: KNeighborsClassifier(n_neighbors=10),\n",
    "    'Linear SVC':\n",
    "        lambda: LinearSVC(penalty='l2', C=1.0, dual=False),\n",
    "    'Logistic regression':\n",
    "        lambda: LogisticRegression(penalty='l2', C=1.0),\n",
    "    'Multi-layer perceptron':\n",
    "        lambda: MLPClassifier(activation='logistic', solver='adam', alpha=0.0001),\n",
    "    'Random forest':\n",
    "        lambda: RandomForestClassifier(n_estimators=50, max_depth=20),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries = []\n",
    "\n",
    "for dataset_name in sorted(datasets.keys()):\n",
    "    for model_name in sorted(models.keys()):\n",
    "        dataset = datasets[dataset_name]\n",
    "        model = models[model_name]()\n",
    "        model.fit(dataset.x_train, dataset.y_train)\n",
    "        score = 'predict_proba' in dir(model)\n",
    "        if score:\n",
    "            y_score = model.predict_proba(dataset.x_test)\n",
    "            y_predicted = [model.classes_[i] for i in np.argmax(y_score, axis=1)]\n",
    "            y_score = y_score[:, list(model.classes_).index(True)]\n",
    "        else:\n",
    "            y_predicted = model.predict(dataset.x_test)\n",
    "            y_score = np.zeros(y_predicted.shape)\n",
    "        summary = {\n",
    "            'Dataset': dataset_name,\n",
    "            'Model': model_name,\n",
    "            'Score': model.score(dataset.x_train, dataset.y_train),\n",
    "        }\n",
    "        summary.update(compute_confusion(dataset.y_test, y_predicted, y_score))\n",
    "        summaries.append(summary)\n",
    "        plot_confusion(dataset.y_test, y_predicted, y_score)\n",
    "        pp.suptitle('{} dataset and {} model'.format(dataset_name, model_name))\n",
    "        print('.', end='')\n",
    "\n",
    "head = ['Dataset', 'Model', 'Score']\n",
    "columns = head + sorted(summaries[0].keys() - head)\n",
    "summaries = pd.DataFrame(summaries, columns=columns)\n",
    "\n",
    "summaries.head(len(summaries))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
