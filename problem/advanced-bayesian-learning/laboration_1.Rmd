---
title: 'Lobaration 1'
output: html_document
---

```{r, message = FALSE}
library(rstan)
library(tidybayes)
library(tidyverse)

options(mc.cores = parallel::detectCores())
rstan_options(auto_write = TRUE)
theme_set(theme_minimal())

set.seed(42)
```

```{r}
url <- 'https://github.com/mattiasvillani/AdvBayesLearnCourse/raw/master/Labs/LidarData.dat'
data <- readr::read_table(url, col_types = list(LogRatio = 'd', Distance = 'd')) %>%
  transmute(x = (Distance - min(Distance)) / diff(range(Distance)),
            y = LogRatio)
```

```{r}
data %>%
  ggplot(aes(x, y)) +
  geom_point(size = 1)
```

# Homoscedastic

```{r}
if (!file.exists('model_1.1.RData')) {
  model <- stan(file = 'model_1.1.stan',
                data = list(d = 1,
                            m = nrow(data),
                            x = as.matrix(data$x),
                            y = data$y))
  save(model, file = 'model_1.1.RData')
} else {
  load('model_1.1.RData')
}
print(model)
```

```{r}
model %>%
  spread_draws(noise_sigma, process_sigma, process_ell) %>%
  pivot_longer(noise_sigma:process_ell) %>%
  mutate(name = factor(name, levels = c('noise_sigma',
                                        'process_sigma',
                                        'process_ell')),
         name = fct_rev(name)) %>%
  ggplot(aes(value, name)) +
  stat_pointintervalh() +
  coord_cartesian(xlim = c(0, 2)) +
  scale_x_continuous(breaks = seq(0, 2, by = 0.2)) +
  theme(axis.title.x = element_blank(),
        axis.title.y = element_blank())
```

```{r}
distance <- function(x, y) {
  m <- nrow(x);
  n <- nrow(y);
  xy <- x %*% t(y);
  xx <- matrix(rep(apply(x * x, 1, sum), n), m, n, byrow = FALSE);
  yy <- matrix(rep(apply(y * y, 1, sum), m), m, n, byrow = TRUE);
  sqrt(pmax(xx + yy - 2 * xy, 0))
}

kernel <- function(x, y, process_sigma, process_ell) {
  process_sigma^2 * exp(-distance(x, y)^2 / process_ell^2 / 2)
}

posterior_predictive <- function(x_new, x, y, noise_sigma, ...) {
  m <- nrow(x);
  n <- nrow(x_new);
  K_11 <- kernel(x, x, ...);
  K_21 <- kernel(x_new, x, ...);
  K_22 <- kernel(x_new, x_new, ...);
  U <- chol(K_11 + diag(noise_sigma^2, m));
  U_inv <- backsolve(U, diag(m));
  K_inv <- U_inv %*% t(U_inv); 
  mu_new <- K_21 %*% K_inv %*% y;
  U_new <- chol(K_22 - K_21 %*% K_inv %*% t(K_21) + diag(noise_sigma^2, n));
  as.vector(mu_new + U_new %*% as.matrix(rnorm(n)))
}

posterior_predictive_map <- function(...) {
  tibble(x = data$x,
         y = posterior_predictive(as.matrix(data$x),
                                  as.matrix(data$x),
                                  data$y, ...))
}

model %>%
  spread_draws(noise_sigma, process_sigma, process_ell) %>%
  transmute(curve = pmap(list(noise_sigma = noise_sigma,
                              process_sigma = process_sigma,
                              process_ell = process_ell),
                         posterior_predictive_map)) %>%
  unnest(curve) %>%
  group_by(x) %>%
  mean_qi() %>%
  ggplot(aes(x, y)) +
  geom_line() +
  geom_point(data = data, size = 1) +
  geom_ribbon(aes(ymin = .lower, ymax = .upper), alpha = 0.1)
```

# Heteroscedastic

```{r}
if (!file.exists('model_1.2.RData')) {
  model <- stan(file = 'model_1.2.stan',
                data = list(d = 1,
                            m = nrow(data),
                            x = as.matrix(data$x),
                            y = data$y))
  save(model, file = 'model_1.2.RData')
} else {
  load('model_1.2.RData')
}
print(model)
```

```{r}
model %>%
  spread_draws(noise_intercept,
               noise_slope[dimension],
               process_sigma,
               process_ell) %>%
  ungroup() %>%
  select(-dimension) %>%
  pivot_longer(noise_intercept:process_ell) %>%
  mutate(name = factor(name, levels = c('noise_intercept',
                                        'noise_slope',
                                        'process_sigma',
                                        'process_ell')),
         name = fct_rev(name)) %>%
  ggplot(aes(value, name)) +
  stat_pointintervalh() +
  coord_cartesian(xlim = c(-10, 5)) +
  scale_x_continuous(breaks = seq(-10, 5, by = 1)) +
  theme(axis.title.x = element_blank(),
        axis.title.y = element_blank())
```

```{r}
posterior_predictive <- function(x_new, noise_intercept, noise_slope) {
  noise_sigma <- sqrt(exp(noise_intercept + x_new %*% noise_slope));
  rnorm(nrow(x_new), 0, noise_sigma)
}

posterior_predictive_map <- function(...) {
  tibble(x = data$x,
         y = posterior_predictive(as.matrix(data$x), ...))
}

model %>%
  spread_draws(noise_intercept, noise_slope[.]) %>%
  transmute(curve = pmap(list(noise_intercept = noise_intercept,
                              noise_slope = noise_slope),
                         posterior_predictive_map)) %>%
  unnest(curve) %>%
  group_by(x) %>%
  mean_qi() %>%
  ggplot(aes(x, y)) +
  geom_line() +
  geom_ribbon(aes(ymin = .lower, ymax = .upper), alpha = 0.1)
```

```{r}
posterior_predictive <- function(x_new, x, y, noise_intercept, noise_slope, ...) {
  m <- nrow(x);
  n <- nrow(x_new);
  K_11 <- kernel(x, x, ...);
  K_21 <- kernel(x_new, x, ...);
  K_22 <- kernel(x_new, x_new, ...);
  U <- chol(K_11 + diag(as.vector(exp(noise_intercept + x %*% noise_slope))));
  U_inv <- backsolve(U, diag(m));
  K_inv <- U_inv %*% t(U_inv);
  mu_new <- K_21 %*% K_inv %*% y;
  U_new <- chol(K_22 - K_21 %*% K_inv %*% t(K_21) +
                diag(as.vector(exp(noise_intercept + x_new %*% noise_slope))));
  as.vector(mu_new + U_new %*% as.matrix(rnorm(n)))
}

posterior_predictive_map <- function(...) {
  tibble(x = data$x,
         y = posterior_predictive(as.matrix(data$x),
                                  as.matrix(data$x),
                                  data$y, ...))
}

model %>%
  spread_draws(noise_intercept, noise_slope[.], process_sigma, process_ell) %>%
  transmute(curve = pmap(list(noise_intercept = noise_intercept,
                              noise_slope = noise_slope,
                              process_sigma = process_sigma,
                              process_ell = process_ell),
                         posterior_predictive_map)) %>%
  unnest(curve) %>%
  group_by(x) %>%
  mean_qi() %>%
  ggplot(aes(x, y)) +
  geom_line() +
  geom_point(data = data, size = 1) +
  geom_ribbon(aes(ymin = .lower, ymax = .upper), alpha = 0.1)
```
