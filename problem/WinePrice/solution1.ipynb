{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from google.datalab.ml import TensorBoard\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "embedding_size = 8\n",
    "epoch_count = 10\n",
    "sequence_length = 170\n",
    "split_ratio = 7 / 3\n",
    "variety_threshold = 500\n",
    "vocabulary_size = 12000\n",
    "wide_size = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/data.csv')\n",
    "data = data[['description', 'variety', 'price']]\n",
    "data = data[~data['price'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varieties = data['variety'].value_counts()\n",
    "varieties = varieties[varieties >= variety_threshold].index\n",
    "data = data[data['variety'].isin(varieties.values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = int(split_ratio / (1 + split_ratio) * len(data))\n",
    "data = data.sample(frac=1, random_state=42)\n",
    "data_train, data_test = data[:split], data[:split]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(data_train['variety'])\n",
    "variety_count = len(encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variety_wide_train = encoder.transform(data_train['variety']).reshape([-1, 1])\n",
    "variety_wide_test = encoder.transform(data_test['variety']).reshape([-1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder()\n",
    "encoder.fit(variety_wide_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variety_wide_train = encoder.transform(variety_wide_train)\n",
    "variety_wide_test = encoder.transform(variety_wide_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(binary=True, dtype=bool, max_features=vocabulary_size)\n",
    "vectorizer.fit(data_train['description']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_wide_train = vectorizer.transform(data_train['description'])\n",
    "description_wide_test = vectorizer.transform(data_test['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(descriptions):\n",
    "    return [\n",
    "        [vectorizer.vocabulary_.get(token, 0) for token in analyzer(description)]\n",
    "        for description in descriptions\n",
    "    ]\n",
    "\n",
    "analyzer = vectorizer.build_analyzer()\n",
    "description_deep_train = convert(data_train['description'].values)\n",
    "description_deep_train = preprocessing.sequence.pad_sequences(description_deep_train, maxlen=sequence_length)\n",
    "description_deep_test = convert(data_test['description'].values)\n",
    "description_deep_test = preprocessing.sequence.pad_sequences(description_deep_test, maxlen=sequence_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep (Actually Another Wide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_input = layers.Input(shape=(sequence_length,))\n",
    "deep_layer = layers.Embedding(vocabulary_size, embedding_size, input_length=sequence_length)(deep_input)\n",
    "deep_layer = layers.Flatten()(deep_layer)\n",
    "deep_output = layers.Dense(1, activation='linear')(deep_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_input = [\n",
    "  layers.Input(shape=(vocabulary_size,)),\n",
    "  layers.Input(shape=(variety_count,)),\n",
    "]\n",
    "wide_layer = layers.concatenate(wide_input)\n",
    "wide_layer = layers.Dense(wide_size, activation='relu')(wide_layer)\n",
    "wide_output = layers.Dense(1)(wide_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Composite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "composite_layer = layers.concatenate([deep_output, wide_output])\n",
    "composite_output = layers.Dense(1)(composite_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "composite_model = models.Model(inputs=[deep_input] + wide_input, outputs=composite_output)\n",
    "composite_model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "composite_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TensorBoard.start('output')\n",
    "tensorboard = callbacks.TensorBoard('output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "composite_model.fit([description_deep_train] + [description_wide_train, variety_wide_train],\n",
    "                    data_train['price'], epochs=epoch_count, batch_size=batch_size,\n",
    "                    callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "composite_model.evaluate([description_deep_test] + [description_wide_test, variety_wide_test],\n",
    "                         data_test['price'], batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = composite_model.predict([description_deep_test] + [description_wide_test, variety_wide_test])\n",
    "predictions = pd.DataFrame({'prediction': predictions.flatten()}, index=data_test.index)\n",
    "predictions = data_test.join(predictions)[['price', 'prediction', 'variety', 'description']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[predictions['variety'] == 'Pinot Noir'].sample(n=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
