{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.sparse import coo_matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_ratio = 7 / 3\n",
    "vocabulary_size = 12000\n",
    "sequence_length = 170\n",
    "dense_unit_count = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/data.csv')\n",
    "data = data[['description', 'variety', 'price']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = int(split_ratio / (1 + split_ratio) * len(data))\n",
    "data = data.sample(frac=1, random_state=42)\n",
    "data_train, data_test = data[:split], data[:split]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(data_train['variety'])\n",
    "variety_count = len(encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variety_wide_train = encoder.transform(data_train['variety']).reshape([-1, 1])\n",
    "variety_wide_test = encoder.transform(data_test['variety']).reshape([-1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder()\n",
    "encoder.fit(variety_wide_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variety_wide_train = encoder.transform(variety_wide_train)\n",
    "variety_wide_test = encoder.transform(variety_wide_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(binary=True, dtype=bool, max_features=vocabulary_size)\n",
    "vectorizer.fit(data_train['description']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(descriptions):\n",
    "    return [\n",
    "        [vectorizer.vocabulary_.get(token, 0) for token in analyzer(description)]\n",
    "        for description in descriptions\n",
    "    ]\n",
    "\n",
    "analyzer = vectorizer.build_analyzer()\n",
    "description_deep_train = convert(data_train['description'].values)\n",
    "description_deep_train = preprocessing.sequence.pad_sequences(description_deep_train, maxlen=sequence_length)\n",
    "description_deep_test = convert(data_test['description'].values)\n",
    "description_deep_test = preprocessing.sequence.pad_sequences(description_deep_test, maxlen=sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_wide_train = vectorizer.transform(data_train['description'])\n",
    "description_wide_test = vectorizer.transform(data_test['description'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wide Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_inputs = layers.Input(shape=(vocabulary_size,))\n",
    "variety_inputs = layers.Input(shape=(variety_count,))\n",
    "wide_inputs = layers.concatenate([description_inputs, variety_inputs])\n",
    "wide_layer = layers.Dense(dense_unit_count, activation='relu')(wide_inputs)\n",
    "wide_outputs = layers.Dense(1)(wide_layer)\n",
    "wide_model = models.Model(inputs=[description_inputs, variety_inputs], outputs=wide_outputs)\n",
    "wide_model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
